{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covid-19 Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pablo Lázaro Herrasti and Rubén Barco Terrones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential, Model \n",
    "from tensorflow.keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D,Conv2D,MaxPooling2D,BatchNormalization\n",
    "from tensorflow.keras import backend as k \n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_covid = 'D:/Covid-19 Data/COVID-19 Radiography Database/'\n",
    "dir_covid_images = dir_covid + 'COVID-19/'\n",
    "dir_normal_images = dir_covid + 'NORMAL/'\n",
    "dir_pneumonia_images = dir_covid + 'Viral Pneumonia/'\n",
    "all_dir_images = [dir_normal_images, dir_covid_images, dir_pneumonia_images]\n",
    "dir_covid_metadata = dir_covid + 'COVID-19.metadata.xlsx'\n",
    "dir_normal_metadata = dir_covid + 'NORMAL.metadata.xlsx'\n",
    "dir_pneumonia_metadata = dir_covid + 'Viral Pneumonia.matadata.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading and preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_covid = pd.read_excel(dir_covid_metadata)\n",
    "metadata_covid['label'] = 0\n",
    "metadata_normal = pd.read_excel(dir_normal_metadata)\n",
    "metadata_normal['label'] = 1\n",
    "metadata_pneumonia = pd.read_excel(dir_pneumonia_metadata)\n",
    "metadata_pneumonia['label'] = 2\n",
    "metadata_all = {dir_covid_images:metadata_covid, dir_normal_images:metadata_normal, dir_pneumonia_images:metadata_pneumonia}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Reading Image data and converting it into pixels and separating class labels\n",
    "Data=[]\n",
    "Label=[]\n",
    "directory='D:/Data_Master/Deep Learning/ChestXRay2017/All'\n",
    "\n",
    "for dir_images in all_dir_images:\n",
    "    files = os.listdir(dir_images)\n",
    "    for index, row in metadata_all[dir_images].iterrows():\n",
    "        Label.append(row['label'])\n",
    "        filename=os.path.join(dir_images, files[index])\n",
    "        im=image.load_img(filename,target_size=(224, 224))\n",
    "        im=np.reshape(im,(224,224,3))\n",
    "        im=im.astype('float32') / 255\n",
    "        Data.append(im)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Test Split\n",
    "X_train, X_1, y_train, y_1 = train_test_split(np.array(Data), np.array(Label), test_size=0.2, random_state=42,stratify=Label)\n",
    "\n",
    "#Train Test Split\n",
    "X_cv, X_test, y_cv, y_test = train_test_split(X_1, y_1, test_size=0.2, random_state=42,stratify=y_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "img_width=224\n",
    "img_height=224\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "    X_train=X_train.reshape(X_train.shape[0],3,img_width,img_height)\n",
    "    X_cv=X_cv.reshape(X_cv.shape[0],3,img_width,img_height)\n",
    "    X_test=X_test.reshape(X_test.shape[0],3,img_width,img_height)\n",
    "    \n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "    X_train=X_train.reshape(X_train.shape[0],img_width,img_height,3)\n",
    "    X_cv=X_cv.reshape(X_cv.shape[0],img_width,img_height,3)\n",
    "    X_test=X_test.reshape(X_test.shape[0],img_width,img_height,3)\n",
    "    \n",
    "del Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Architecture for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 112, 112, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 56, 56, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                6422592   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 6,516,035\n",
      "Trainable params: 6,516,035\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv2D(32, 3, input_shape=input_shape, activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(2))\n",
    "model.add(Conv2D(64, 3, activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(2))\n",
    "model.add(Conv2D(128, 3, activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2324 samples, validate on 464 samples\n",
      "Epoch 1/4\n",
      "2324/2324 [==============================] - 146s 63ms/sample - loss: 0.6795 - acc: 0.7207 - val_loss: 0.3495 - val_acc: 0.8793\n",
      "Epoch 2/4\n",
      "2324/2324 [==============================] - 136s 59ms/sample - loss: 0.2772 - acc: 0.9015 - val_loss: 0.1585 - val_acc: 0.9397\n",
      "Epoch 3/4\n",
      "2324/2324 [==============================] - 137s 59ms/sample - loss: 0.1796 - acc: 0.9398 - val_loss: 0.1257 - val_acc: 0.9526\n",
      "Epoch 4/4\n",
      "2324/2324 [==============================] - 137s 59ms/sample - loss: 0.1229 - acc: 0.9583 - val_loss: 0.1321 - val_acc: 0.9461\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2229bcb2e10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 4\n",
    "batch_size = 32\n",
    "model.fit(x=X_train, y=y_train, batch_size=batch_size, epochs=n_epochs, validation_data=(X_cv,y_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Multiclass prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final train accuracy is  96.90189328743546 %\n",
      "The final validation accuracy is  94.61206896551724 %\n",
      "The final test accuracy is  94.87179487179486 %\n"
     ]
    }
   ],
   "source": [
    "train_acc = accuracy_score(model.predict_classes(X_train), y_train)\n",
    "valid_acc = accuracy_score(model.predict_classes(X_cv), y_cv)\n",
    "test_acc = accuracy_score(model.predict_classes(X_test), y_test)\n",
    "print(\"The final train accuracy is \",train_acc*100,\"%\")\n",
    "print(\"The final validation accuracy is \",valid_acc*100,\"%\")\n",
    "print(\"The final test accuracy is \",test_acc*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Binary prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = accuracy_score((model.predict(X_train)>0.5).astype(int), y_train)\n",
    "valid_acc = accuracy_score((model.predict(X_cv)>0.5).astype(int), y_cv)\n",
    "test_acc = accuracy_score((model.predict(X_test)>0.5).astype(int), y_test)\n",
    "print(\"The final train accuracy is \",train_acc*100,\"%\")\n",
    "print(\"The final validation accuracy is \",valid_acc*100,\"%\")\n",
    "print(\"The final test accuracy is \",test_acc*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Covid accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final test accuracy for COVID-19 is  98.14814814814815 %\n"
     ]
    }
   ],
   "source": [
    "X_covid = X_test[y_test == 0]\n",
    "y_covid = y_test[y_test == 0]\n",
    "test_acc = accuracy_score(model.predict_classes(X_covid), y_covid)\n",
    "print(\"The final test accuracy for COVID-19 is \",test_acc*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final test accuracy for NORMAL is  98.14814814814815 %\n"
     ]
    }
   ],
   "source": [
    "X_normal = X_test[y_test == 1]\n",
    "y_normal = y_test[y_test == 1]\n",
    "test_acc = accuracy_score(model.predict_classes(X_normal), y_normal)\n",
    "print(\"The final test accuracy for NORMAL is \",test_acc*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final test accuracy for PNEUMONIA is  92.5925925925926 %\n"
     ]
    }
   ],
   "source": [
    "X_pneumonia = X_test[y_test == 2]\n",
    "y_pneumonia = y_test[y_test == 2]\n",
    "test_acc = accuracy_score(model.predict_classes(X_pneumonia), y_pneumonia)\n",
    "print(\"The final test accuracy for PNEUMONIA is \",test_acc*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
